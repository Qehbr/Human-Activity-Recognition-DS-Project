{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from CNN.CNN import MultivariateCNN\n",
    "from models_utils.Datasets import *\n",
    "from models_utils.GLOBALS import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from CNN.cnn_utils import get_train_data, train_1D_cnn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:39:43.092199800Z",
     "start_time": "2024-02-20T13:39:40.264790400Z"
    }
   },
   "id": "1044635a7c33d70",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get train data\n",
    "train_data = pd.read_csv('csv/train.csv', index_col=0)\n",
    "train_data['activity'] = train_data['activity'].map(activity_id_mapping)\n",
    "data_type_1 = train_data[train_data['sensor'] == 'vicon'].reset_index()\n",
    "data_type_2 = train_data[train_data['sensor'] == 'smartwatch'].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:39:43.128723600Z",
     "start_time": "2024-02-20T13:39:43.093699100Z"
    }
   },
   "id": "d8f0cf28027bd353",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sizes of padding/cutting\n",
    "target_size_type1 = 3000\n",
    "target_size_type2 = 1169"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:39:43.130918300Z",
     "start_time": "2024-02-20T13:39:43.129913100Z"
    }
   },
   "id": "fa1de3b0f44ead8b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Saving Best Model with loss: 1.8948339088396593\n",
      "Epoch [1/30], Epoch Duration: 30.69 seconds\n",
      "Epoch [1/30], Training Loss: 2.8453, Training Accuracy: 15.38%\n",
      "Epoch [1/30], Validation Loss: 1.8948, Validation Accuracy: 19.13%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.8002430417320945\n",
      "Epoch [2/30], Epoch Duration: 29.43 seconds\n",
      "Epoch [2/30], Training Loss: 1.8566, Training Accuracy: 22.85%\n",
      "Epoch [2/30], Validation Loss: 1.8002, Validation Accuracy: 22.82%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.745712551203641\n",
      "Epoch [3/30], Epoch Duration: 29.64 seconds\n",
      "Epoch [3/30], Training Loss: 1.7717, Training Accuracy: 26.70%\n",
      "Epoch [3/30], Validation Loss: 1.7457, Validation Accuracy: 27.27%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.67983985489065\n",
      "Epoch [4/30], Epoch Duration: 29.39 seconds\n",
      "Epoch [4/30], Training Loss: 1.7103, Training Accuracy: 29.22%\n",
      "Epoch [4/30], Validation Loss: 1.6798, Validation Accuracy: 28.90%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.6655739085240797\n",
      "Epoch [5/30], Epoch Duration: 29.80 seconds\n",
      "Epoch [5/30], Training Loss: 1.6664, Training Accuracy: 30.67%\n",
      "Epoch [5/30], Validation Loss: 1.6656, Validation Accuracy: 30.96%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.6170204037969762\n",
      "Epoch [6/30], Epoch Duration: 29.25 seconds\n",
      "Epoch [6/30], Training Loss: 1.6166, Training Accuracy: 33.27%\n",
      "Epoch [6/30], Validation Loss: 1.6170, Validation Accuracy: 31.92%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.5696346434679898\n",
      "Epoch [7/30], Epoch Duration: 29.56 seconds\n",
      "Epoch [7/30], Training Loss: 1.5777, Training Accuracy: 35.06%\n",
      "Epoch [7/30], Validation Loss: 1.5696, Validation Accuracy: 33.63%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.5016450854864987\n",
      "Epoch [8/30], Epoch Duration: 34.41 seconds\n",
      "Epoch [8/30], Training Loss: 1.5010, Training Accuracy: 38.74%\n",
      "Epoch [8/30], Validation Loss: 1.5016, Validation Accuracy: 37.58%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.3899153470993042\n",
      "Epoch [9/30], Epoch Duration: 37.18 seconds\n",
      "Epoch [9/30], Training Loss: 1.3784, Training Accuracy: 45.27%\n",
      "Epoch [9/30], Validation Loss: 1.3899, Validation Accuracy: 44.90%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.2641325105320325\n",
      "Epoch [10/30], Epoch Duration: 37.20 seconds\n",
      "Epoch [10/30], Training Loss: 1.1858, Training Accuracy: 54.61%\n",
      "Epoch [10/30], Validation Loss: 1.2641, Validation Accuracy: 49.45%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.1417311484163457\n",
      "Epoch [11/30], Epoch Duration: 36.55 seconds\n",
      "Epoch [11/30], Training Loss: 0.9694, Training Accuracy: 65.04%\n",
      "Epoch [11/30], Validation Loss: 1.1417, Validation Accuracy: 57.27%\n",
      "--------------\n",
      "Saving Best Model with loss: 1.0917196300896732\n",
      "Epoch [12/30], Epoch Duration: 36.68 seconds\n",
      "Epoch [12/30], Training Loss: 0.8294, Training Accuracy: 71.20%\n",
      "Epoch [12/30], Validation Loss: 1.0917, Validation Accuracy: 61.39%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.9813936379822817\n",
      "Epoch [13/30], Epoch Duration: 36.81 seconds\n",
      "Epoch [13/30], Training Loss: 0.6201, Training Accuracy: 78.57%\n",
      "Epoch [13/30], Validation Loss: 0.9814, Validation Accuracy: 67.65%\n",
      "--------------\n",
      "Epoch [14/30], Epoch Duration: 35.93 seconds\n",
      "Epoch [14/30], Training Loss: 0.4884, Training Accuracy: 83.86%\n",
      "Epoch [14/30], Validation Loss: 0.9975, Validation Accuracy: 66.76%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.9416514120318673\n",
      "Epoch [15/30], Epoch Duration: 37.78 seconds\n",
      "Epoch [15/30], Training Loss: 0.3826, Training Accuracy: 87.93%\n",
      "Epoch [15/30], Validation Loss: 0.9417, Validation Accuracy: 72.98%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.9124078588052229\n",
      "Epoch [16/30], Epoch Duration: 33.65 seconds\n",
      "Epoch [16/30], Training Loss: 0.2978, Training Accuracy: 90.48%\n",
      "Epoch [16/30], Validation Loss: 0.9124, Validation Accuracy: 76.11%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.9044384089383212\n",
      "Epoch [17/30], Epoch Duration: 29.92 seconds\n",
      "Epoch [17/30], Training Loss: 0.2561, Training Accuracy: 92.05%\n",
      "Epoch [17/30], Validation Loss: 0.9044, Validation Accuracy: 77.71%\n",
      "--------------\n",
      "Epoch [18/30], Epoch Duration: 29.42 seconds\n",
      "Epoch [18/30], Training Loss: 0.2061, Training Accuracy: 93.34%\n",
      "Epoch [18/30], Validation Loss: 0.9400, Validation Accuracy: 78.71%\n",
      "--------------\n",
      "Epoch [19/30], Epoch Duration: 29.81 seconds\n",
      "Epoch [19/30], Training Loss: 0.1853, Training Accuracy: 93.87%\n",
      "Epoch [19/30], Validation Loss: 0.9759, Validation Accuracy: 78.67%\n",
      "--------------\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch [20/30], Epoch Duration: 30.05 seconds\n",
      "Epoch [20/30], Training Loss: 0.1910, Training Accuracy: 93.97%\n",
      "Epoch [20/30], Validation Loss: 1.0204, Validation Accuracy: 77.21%\n",
      "--------------\n",
      "Epoch [21/30], Epoch Duration: 29.51 seconds\n",
      "Epoch [21/30], Training Loss: 0.1252, Training Accuracy: 96.22%\n",
      "Epoch [21/30], Validation Loss: 0.9953, Validation Accuracy: 79.95%\n",
      "--------------\n",
      "Epoch [22/30], Epoch Duration: 29.83 seconds\n",
      "Epoch [22/30], Training Loss: 0.1169, Training Accuracy: 96.28%\n",
      "Epoch [22/30], Validation Loss: 0.9997, Validation Accuracy: 80.48%\n",
      "--------------\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch [23/30], Epoch Duration: 29.59 seconds\n",
      "Epoch [23/30], Training Loss: 0.1154, Training Accuracy: 96.52%\n",
      "Epoch [23/30], Validation Loss: 1.0129, Validation Accuracy: 80.23%\n",
      "--------------\n",
      "Epoch [24/30], Epoch Duration: 30.04 seconds\n",
      "Epoch [24/30], Training Loss: 0.1108, Training Accuracy: 96.76%\n",
      "Epoch [24/30], Validation Loss: 1.0071, Validation Accuracy: 80.13%\n",
      "--------------\n",
      "Epoch [25/30], Epoch Duration: 30.15 seconds\n",
      "Epoch [25/30], Training Loss: 0.1103, Training Accuracy: 96.74%\n",
      "Epoch [25/30], Validation Loss: 1.0081, Validation Accuracy: 80.09%\n",
      "--------------\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch [26/30], Epoch Duration: 30.01 seconds\n",
      "Epoch [26/30], Training Loss: 0.1097, Training Accuracy: 96.72%\n",
      "Epoch [26/30], Validation Loss: 1.0079, Validation Accuracy: 80.02%\n",
      "--------------\n",
      "Epoch [27/30], Epoch Duration: 29.35 seconds\n",
      "Epoch [27/30], Training Loss: 0.1091, Training Accuracy: 96.76%\n",
      "Epoch [27/30], Validation Loss: 1.0088, Validation Accuracy: 80.02%\n",
      "--------------\n",
      "Epoch [28/30], Epoch Duration: 29.95 seconds\n",
      "Epoch [28/30], Training Loss: 0.1091, Training Accuracy: 96.76%\n",
      "Epoch [28/30], Validation Loss: 1.0091, Validation Accuracy: 80.02%\n",
      "--------------\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch [29/30], Epoch Duration: 30.13 seconds\n",
      "Epoch [29/30], Training Loss: 0.1091, Training Accuracy: 96.75%\n",
      "Epoch [29/30], Validation Loss: 1.0090, Validation Accuracy: 80.02%\n",
      "--------------\n",
      "Epoch [30/30], Epoch Duration: 30.15 seconds\n",
      "Epoch [30/30], Training Loss: 0.1089, Training Accuracy: 96.76%\n",
      "Epoch [30/30], Validation Loss: 1.0091, Validation Accuracy: 80.02%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultivariateCNN:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 1, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 288000]) from checkpoint, the shape in current model is torch.Size([512, 96000]).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m train_or_load_autoencoders \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_or_load_autoencoders \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m----> 4\u001B[0m     model_CNN_type1 \u001B[38;5;241m=\u001B[39m train_1D_cnn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mType1Only1DCNN\u001B[39m\u001B[38;5;124m'\u001B[39m, data_type_1, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m, target_size_type1, \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m      5\u001B[0m     model_CNN_type2 \u001B[38;5;241m=\u001B[39m train_1D_cnn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mType2Only1DCNN\u001B[39m\u001B[38;5;124m'\u001B[39m, data_type_2, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m, target_size_type2, \u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m train_or_load_autoencoders \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearningWorkshopEx2\\CNN\\cnn_utils.py:334\u001B[0m, in \u001B[0;36mtrain_1D_cnn\u001B[1;34m(save_name, data, data_type, data_size, num_epochs, batch_size, learning_rate)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;66;03m# load best model\u001B[39;00m\n\u001B[0;32m    333\u001B[0m model_CNN \u001B[38;5;241m=\u001B[39m MultivariateCNN(\u001B[38;5;241m3\u001B[39m, data_size, \u001B[38;5;241m18\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m--> 334\u001B[0m model_CNN\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_CNN\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2147\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2148\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2149\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2152\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2153\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for MultivariateCNN:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 1, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 288000]) from checkpoint, the shape in current model is torch.Size([512, 96000])."
     ]
    }
   ],
   "source": [
    "# train or load models\n",
    "train_or_load_autoencoders = 'train'\n",
    "if train_or_load_autoencoders == 'train':\n",
    "    model_CNN_type1 = train_1D_cnn('Type1Only1DCNN', data_type_1, '1', target_size_type1, 30, 64, 0.001)\n",
    "    model_CNN_type2 = train_1D_cnn('Type2Only1DCNN', data_type_2, '2', target_size_type2, 20, 64, 0.001)\n",
    "elif train_or_load_autoencoders == 'load':\n",
    "    model_CNN_type1 = MultivariateCNN(3, target_size_type1, 18).to(device)\n",
    "    model_CNN_type1.load_state_dict(torch.load('Type1Only1DCNN.pth'))\n",
    "    model_CNN_type2 = MultivariateCNN(3, target_size_type2, 18).to(device)\n",
    "    model_CNN_type2.load_state_dict(torch.load(f'Type2Only1DCNN.pth'))\n",
    "else:\n",
    "    raise ValueError('Wrong train or load')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:55:47.344534100Z",
     "start_time": "2024-02-20T13:39:43.132918500Z"
    }
   },
   "id": "58a5f2d600460357",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Saving Best Model with loss: 0.7674008317683872\n",
      "Epoch [1/20], Epoch Duration: 295.83 seconds\n",
      "Epoch [1/20], Training Loss: 1.2405, Training Accuracy: 56.91%\n",
      "Epoch [1/20], Validation Loss: 0.7674, Validation Accuracy: 71.75%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.5778459253018362\n",
      "Epoch [2/20], Epoch Duration: 130.98 seconds\n",
      "Epoch [2/20], Training Loss: 0.5090, Training Accuracy: 81.39%\n",
      "Epoch [2/20], Validation Loss: 0.5778, Validation Accuracy: 80.51%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.4035792191300476\n",
      "Epoch [3/20], Epoch Duration: 130.61 seconds\n",
      "Epoch [3/20], Training Loss: 0.2538, Training Accuracy: 91.34%\n",
      "Epoch [3/20], Validation Loss: 0.4036, Validation Accuracy: 88.37%\n",
      "--------------\n",
      "Epoch [4/20], Epoch Duration: 128.41 seconds\n",
      "Epoch [4/20], Training Loss: 0.1417, Training Accuracy: 95.24%\n",
      "Epoch [4/20], Validation Loss: 0.4317, Validation Accuracy: 89.25%\n",
      "--------------\n",
      "Saving Best Model with loss: 0.3591478703576222\n",
      "Epoch [5/20], Epoch Duration: 136.19 seconds\n",
      "Epoch [5/20], Training Loss: 0.0909, Training Accuracy: 96.95%\n",
      "Epoch [5/20], Validation Loss: 0.3591, Validation Accuracy: 90.95%\n",
      "--------------\n",
      "Epoch [6/20], Epoch Duration: 134.21 seconds\n",
      "Epoch [6/20], Training Loss: 0.0923, Training Accuracy: 96.92%\n",
      "Epoch [6/20], Validation Loss: 0.4190, Validation Accuracy: 90.66%\n",
      "--------------\n",
      "Epoch [7/20], Epoch Duration: 132.01 seconds\n",
      "Epoch [7/20], Training Loss: 0.0623, Training Accuracy: 98.14%\n",
      "Epoch [7/20], Validation Loss: 0.4524, Validation Accuracy: 90.33%\n",
      "--------------\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch [8/20], Epoch Duration: 133.53 seconds\n",
      "Epoch [8/20], Training Loss: 0.0546, Training Accuracy: 98.20%\n",
      "Epoch [8/20], Validation Loss: 0.5228, Validation Accuracy: 90.07%\n",
      "--------------\n",
      "Epoch [9/20], Epoch Duration: 132.98 seconds\n",
      "Epoch [9/20], Training Loss: 0.0128, Training Accuracy: 99.69%\n",
      "Epoch [9/20], Validation Loss: 0.3894, Validation Accuracy: 93.89%\n",
      "--------------\n",
      "Epoch [10/20], Epoch Duration: 131.73 seconds\n",
      "Epoch [10/20], Training Loss: 0.0073, Training Accuracy: 99.87%\n",
      "Epoch [10/20], Validation Loss: 0.3956, Validation Accuracy: 93.98%\n",
      "--------------\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch [11/20], Epoch Duration: 130.49 seconds\n",
      "Epoch [11/20], Training Loss: 0.0061, Training Accuracy: 99.89%\n",
      "Epoch [11/20], Validation Loss: 0.4015, Validation Accuracy: 94.09%\n",
      "--------------\n",
      "Epoch [12/20], Epoch Duration: 131.19 seconds\n",
      "Epoch [12/20], Training Loss: 0.0051, Training Accuracy: 99.89%\n",
      "Epoch [12/20], Validation Loss: 0.4031, Validation Accuracy: 94.02%\n",
      "--------------\n",
      "Epoch [13/20], Epoch Duration: 132.64 seconds\n",
      "Epoch [13/20], Training Loss: 0.0050, Training Accuracy: 99.91%\n",
      "Epoch [13/20], Validation Loss: 0.4041, Validation Accuracy: 94.03%\n",
      "--------------\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch [14/20], Epoch Duration: 129.55 seconds\n",
      "Epoch [14/20], Training Loss: 0.0048, Training Accuracy: 99.91%\n",
      "Epoch [14/20], Validation Loss: 0.4054, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch [15/20], Epoch Duration: 129.47 seconds\n",
      "Epoch [15/20], Training Loss: 0.0047, Training Accuracy: 99.92%\n",
      "Epoch [15/20], Validation Loss: 0.4054, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch [16/20], Epoch Duration: 132.02 seconds\n",
      "Epoch [16/20], Training Loss: 0.0047, Training Accuracy: 99.91%\n",
      "Epoch [16/20], Validation Loss: 0.4054, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch [17/20], Epoch Duration: 130.72 seconds\n",
      "Epoch [17/20], Training Loss: 0.0046, Training Accuracy: 99.92%\n",
      "Epoch [17/20], Validation Loss: 0.4055, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch [18/20], Epoch Duration: 128.99 seconds\n",
      "Epoch [18/20], Training Loss: 0.0046, Training Accuracy: 99.92%\n",
      "Epoch [18/20], Validation Loss: 0.4055, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch [19/20], Epoch Duration: 130.39 seconds\n",
      "Epoch [19/20], Training Loss: 0.0046, Training Accuracy: 99.92%\n",
      "Epoch [19/20], Validation Loss: 0.4056, Validation Accuracy: 94.00%\n",
      "--------------\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch [20/20], Epoch Duration: 131.52 seconds\n",
      "Epoch [20/20], Training Loss: 0.0046, Training Accuracy: 99.92%\n",
      "Epoch [20/20], Validation Loss: 0.4056, Validation Accuracy: 94.00%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultivariateCNN:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 1, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 112128]) from checkpoint, the shape in current model is torch.Size([512, 37376]).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_CNN_type2 \u001B[38;5;241m=\u001B[39m train_1D_cnn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mType2Only1DCNN\u001B[39m\u001B[38;5;124m'\u001B[39m, data_type_2, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m, target_size_type2, \u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m0.001\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearningWorkshopEx2\\CNN\\cnn_utils.py:334\u001B[0m, in \u001B[0;36mtrain_1D_cnn\u001B[1;34m(save_name, data, data_type, data_size, num_epochs, batch_size, learning_rate)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;66;03m# load best model\u001B[39;00m\n\u001B[0;32m    333\u001B[0m model_CNN \u001B[38;5;241m=\u001B[39m MultivariateCNN(\u001B[38;5;241m3\u001B[39m, data_size, \u001B[38;5;241m18\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m--> 334\u001B[0m model_CNN\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_CNN\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2147\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2148\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2149\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2152\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2153\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for MultivariateCNN:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 1, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 112128]) from checkpoint, the shape in current model is torch.Size([512, 37376])."
     ]
    }
   ],
   "source": [
    "model_CNN_type2 = train_1D_cnn('Type2Only1DCNN', data_type_2, '2', target_size_type2, 20, 64, 0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:52:06.053047500Z",
     "start_time": "2024-02-20T14:05:31.035714700Z"
    }
   },
   "id": "401f3b7dc68a2d71",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_Only_CNN_type1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m     data_type_1, data_type_2 \u001B[38;5;241m=\u001B[39m get_train_data([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_Only_CNN\u001B[39m\u001B[38;5;124m'\u001B[39m], model_CNN_type1, model_CNN_type2,\n\u001B[0;32m      6\u001B[0m                                               embedding_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m18\u001B[39m, is_autoencoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m calculate_or_load_train_data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m----> 8\u001B[0m     data_type_1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_Only_CNN_type1.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m     data_type_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_Only_CNN_type2.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    945\u001B[0m )\n\u001B[0;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m   1706\u001B[0m     f,\n\u001B[0;32m   1707\u001B[0m     mode,\n\u001B[0;32m   1708\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1709\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1710\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   1711\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[0;32m   1712\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1713\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1714\u001B[0m )\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\pandas\\io\\common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    864\u001B[0m             handle,\n\u001B[0;32m    865\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    866\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    867\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    868\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m         )\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'train_Only_CNN_type1.csv'"
     ]
    }
   ],
   "source": [
    "# calculate or load train_data\n",
    "embedding_names = [f'embedding_feature_{i + 1}' for i in range(18)]\n",
    "calculate_or_load_train_data = 'load'\n",
    "if calculate_or_load_train_data == 'calculate':\n",
    "    data_type_1, data_type_2 = get_train_data(['train_Only_CNN'], model_CNN_type1, model_CNN_type2,\n",
    "                                              embedding_size=18, is_autoencoder=False)\n",
    "elif calculate_or_load_train_data == 'load':\n",
    "    data_type_1 = pd.read_csv('train_Only_CNN_type1.csv')\n",
    "    data_type_2 = pd.read_csv('train_Only_CNN_type2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:37:24.636378300Z",
     "start_time": "2024-02-20T13:37:23.172228100Z"
    }
   },
   "id": "7a61cf3ec20af066",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get and save results for test data\n",
    "results_list = []\n",
    "for i, file_id in enumerate(pd.read_csv('sample_submission.csv')['sample_id'].to_list()):\n",
    "\n",
    "    class_path = os.path.join(files_directory, f\"{file_id}.csv\")\n",
    "    new_data = pd.read_csv(class_path)\n",
    "\n",
    "    if new_data.shape[1] == 3:\n",
    "        if len(new_data) < 4000:\n",
    "            new_data = pad_sequence(new_data, 4000)\n",
    "        new_data = torch.tensor(new_data.values, dtype=torch.float32).to(device)\n",
    "        normalized_new_data = (new_data - min_values_type1) / (max_values_type1 - min_values_type1 + 1e-6)\n",
    "        normalized_new_data = normalized_new_data.transpose(0, 1)\n",
    "        logits = model_CNN_type1(normalized_new_data)\n",
    "\n",
    "\n",
    "    else:\n",
    "        new_data = new_data[new_data.iloc[:, 0] == 'acceleration [m/s/s]'].iloc[:, 1:]\n",
    "        if len(new_data) < 1350:\n",
    "            new_data = pad_sequence(new_data, 1350)\n",
    "        new_data = torch.tensor(new_data.values, dtype=torch.float32).to(device)\n",
    "        normalized_new_data = (new_data - min_values_type2) / (max_values_type2 - min_values_type2 + 1e-6)\n",
    "        normalized_new_data = normalized_new_data.transpose(0, 1)\n",
    "\n",
    "        logits = model_CNN_type2(normalized_new_data)\n",
    "\n",
    "    predictions = F.softmax(logits, dim=1)\n",
    "    res_dict = {activity: predictions.squeeze()[id].item() for id, activity in id_activity_mapping.items()}\n",
    "\n",
    "    result_dict = {label: res_dict.get(label, 0) for label in activity_id_mapping.keys()}\n",
    "    result_dict['sample_id'] = file_id\n",
    "    results_list.append(result_dict)\n",
    "results = pd.DataFrame(results_list, columns=['sample_id'] + list(activity_id_mapping.keys()))\n",
    "results.fillna(0).to_csv('results_raw_cnn.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:47:49.042127200Z",
     "start_time": "2024-02-16T23:35:50.155064800Z"
    }
   },
   "id": "7ca4b578d0e4f4c",
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
