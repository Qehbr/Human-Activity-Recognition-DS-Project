{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models_utils.Datasets import *\n",
    "from models_utils.GLOBALS import *\n",
    "import torch.nn.functional as F\n",
    "from CNN.CNN import MultivariateCNN\n",
    "from CNN.cnn_utils import train_cnn, get_train_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1044635a7c33d70",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get train data\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "train_data['activity'] = train_data['activity'].map(activity_id_mapping)\n",
    "data_type_1 = train_data[train_data['sensor'] == 'vicon'].reset_index()\n",
    "data_type_2 = train_data[train_data['sensor'] == 'smartwatch'].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:54:34.202543300Z",
     "start_time": "2024-02-19T20:54:34.165377100Z"
    }
   },
   "id": "d8f0cf28027bd353",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sizes of padding/cutting\n",
    "target_size_type1 = 3000\n",
    "target_size_type2 = 1169"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1de3b0f44ead8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# train or load models\n",
    "train_or_load_autoencoders = 'load'\n",
    "if train_or_load_autoencoders == 'train':\n",
    "    model_CNN_type1 = train_cnn('Type1OnlyCNN', data_type_1, '1', target_size_type1, 30, 64, 0.001)\n",
    "    model_CNN_type2 = train_cnn('Type2OnlyCNN', data_type_2, '2', target_size_type2, 20, 64, 0.001)\n",
    "elif train_or_load_autoencoders == 'load':\n",
    "    model_CNN_type1 = MultivariateCNN(3, target_size_type1, 18).to(device)\n",
    "    model_CNN_type1.load_state_dict(torch.load('Type1OnlyCNN.pth'))\n",
    "    model_CNN_type2 = MultivariateCNN(3, target_size_type2, 18).to(device)\n",
    "    model_CNN_type2.load_state_dict(torch.load(f'Type2OnlyCNN.pth'))\n",
    "else:\n",
    "    raise ValueError('Wrong train or load')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58a5f2d600460357"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# calculate or load train_data\n",
    "embedding_names = [f'embedding_feature_{i + 1}' for i in range(18)]\n",
    "calculate_or_load_train_data = 'load'\n",
    "if calculate_or_load_train_data == 'calculate':\n",
    "    data_type_1, data_type_2 = get_train_data(['train_Only_CNN'], model_CNN_type1, model_CNN_type2,\n",
    "                                              embedding_size=18, is_autoencoder=False)\n",
    "elif calculate_or_load_train_data == 'load':\n",
    "    data_type_1 = pd.read_csv('train_Only_CNN_type1.csv')\n",
    "    data_type_2 = pd.read_csv('train_Only_CNN_type2.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a61cf3ec20af066"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get and save results for test data\n",
    "results_list = []\n",
    "for i, file_id in enumerate(pd.read_csv('sample_submission.csv')['sample_id'].to_list()):\n",
    "\n",
    "    class_path = os.path.join(files_directory, f\"{file_id}.csv\")\n",
    "    new_data = pd.read_csv(class_path)\n",
    "\n",
    "    if new_data.shape[1] == 3:\n",
    "        if len(new_data) < 4000:\n",
    "            new_data = pad_sequence(new_data, 4000)\n",
    "        new_data = torch.tensor(new_data.values, dtype=torch.float32).to(device)\n",
    "        normalized_new_data = (new_data - min_values_type1) / (max_values_type1 - min_values_type1 + 1e-6)\n",
    "        normalized_new_data = normalized_new_data.transpose(0, 1)\n",
    "        logits = model_CNN_type1(normalized_new_data)\n",
    "\n",
    "\n",
    "    else:\n",
    "        new_data = new_data[new_data.iloc[:, 0] == 'acceleration [m/s/s]'].iloc[:, 1:]\n",
    "        if len(new_data) < 1350:\n",
    "            new_data = pad_sequence(new_data, 1350)\n",
    "        new_data = torch.tensor(new_data.values, dtype=torch.float32).to(device)\n",
    "        normalized_new_data = (new_data - min_values_type2) / (max_values_type2 - min_values_type2 + 1e-6)\n",
    "        normalized_new_data = normalized_new_data.transpose(0, 1)\n",
    "\n",
    "        logits = model_CNN_type2(normalized_new_data)\n",
    "\n",
    "    predictions = F.softmax(logits, dim=1)\n",
    "    res_dict = {activity: predictions.squeeze()[id].item() for id, activity in id_activity_mapping.items()}\n",
    "\n",
    "    result_dict = {label: res_dict.get(label, 0) for label in activity_id_mapping.keys()}\n",
    "    result_dict['sample_id'] = file_id\n",
    "    results_list.append(result_dict)\n",
    "results = pd.DataFrame(results_list, columns=['sample_id'] + list(activity_id_mapping.keys()))\n",
    "results.fillna(0).to_csv('results_raw_cnn.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:47:49.042127200Z",
     "start_time": "2024-02-16T23:35:50.155064800Z"
    }
   },
   "id": "7ca4b578d0e4f4c",
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
